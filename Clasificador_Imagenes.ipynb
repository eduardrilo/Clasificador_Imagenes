{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNPWJNHBbXXB"
      },
      "source": [
        "#MNIST Fashion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "\n",
        "La clasificación es ampliamente usada en inteligencia artificial, en varios campos. Existen varias maneras de construir clasificadores usando técnicas de machine learning y deep learning.\n",
        "\n",
        "Esta guia usa [tf.keras](https://www.tensorflow.org/guide/keras), una API de alto nivel para construir y entrenar modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0tMfX2vR0uD"
      },
      "source": [
        "## Instalar e importar dependencias\n",
        "\n",
        "Usaremos un conjunto de datos de la página [TensorFlow Datasets](https://www.tensorflow.org/datasets/). Esta API simplifica el descargar y acceder los datos. También provee muchos conjuntos de datos. También usaremos algunas librerías auxiliares."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7mUJVqcINSM"
      },
      "source": [
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOA5qUl9_-Go"
      },
      "source": [
        "Importamos las dependencias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UbK0Uq7GWaO"
      },
      "source": [
        "# Import Tensorflow\n",
        "import tensorflow as tf\n",
        "# Import TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Helper libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfNnMTg7AOpL"
      },
      "source": [
        "Ademas, configuramos la salida de tensorflow para que solo nos muestre los errores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "590z76KRGtKk"
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Importar el Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "Esta guia usa el set de datos [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), el cual contiene 70.000 imagenes en blanco y negro en 10 categorías. Cada imagen es un articulo de ropa de tamaño (28 $\\times$ 28 pixeles), como se muestra a continuación:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Imágenes del Fashion MNIST\" width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figura 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Usaremos 60.000 imagenes para entrenar la red neuronal y 10.000 imagenes para evaluar el desempeño de la red. Puedes acceder al set de datos directamente, usando la [API](https://www.tensorflow.org/datasets)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UOvA-oRBPC-"
      },
      "source": [
        "La siguiente linea importa y desempaqueta el conjunto de datos. En este caso, la función recibe los siguientes parámetros:\n",
        "\n",
        "*   `name=\"fashion_mnist\"`: El nombre del conjunto de datos que queremos descargar. Este nombre tiene que ser exacto para que se pueda encontrar el conjunto de datos. Puedes ver los conjuntos de datos y sus nombres [aquí](https://www.tensorflow.org/datasets).\n",
        "*   `as_supervised=True`: El conjunto de datos obtenido tendrá una estructura de tupla (input, label). Si `as_supervised` fuera `False`, el conjunto de datos obtenido tendría un diccionario con todas las características.\n",
        "\n",
        "*   `with_info=True`: Si es `True`, la función retornará una tupla donde el primer elemento sería la información del conjunto de datos y el segundo la metadata relevante al set de datos.\n",
        "\n",
        "Mas argumentos pueden ser encontrados en la siguiente [documentación](https://www.tensorflow.org/datasets/api_docs/python/tfds/load)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "source": [
        "dataset, metadata = tfds.load(name='fashion_mnist', as_supervised=True, with_info=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtftlQxXDkaB"
      },
      "source": [
        "Dividimos el conjunto de datos en entrenamiento (training set) y prueba (test set). Dijimos que dividiríamos el conjunto de datos en 60.000 imágenes de entrenamiento y 10.000 de prueba. No necesitaremos hacer esto último debido a que el conjunto de datos ya se encuentra dividido.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHZzHM9PBL4K"
      },
      "source": [
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "La línea de código anterior carga el conjunto de datos y retorna el metadata junto con los conjuntos de datos de entrenamiento y pruebas.\n",
        "\n",
        "* El modelo es entrenado utilizando el `train_dataset`.\n",
        "* El modelo es probado con el `test_dataset`.\n",
        "\n",
        "Las imagenes son arreglos de 28 $\\times$ 28 pixeles. Cada pixel está en el rango `[0, 255]` en tonalidad que va del blanco al negro.\n",
        "\n",
        "Los `labels` o etiquetas de las imágenes son arreglos de enteros, en el rango `[0, 9]`. Estos corresponden a la clase de prenda que la imagen representa:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>Polera/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Pantalón</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Chaleco</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Vestido</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Abrigo</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandalia</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Camisa</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Zapatilla</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bolso</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Bota</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Cada imagen corresponde a una clase en específico. Como los nombres de las clases no están incluidos en el set de datos, los guardamos para mostrarlos después."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "source": [
        "class_names = ['Polera/top', 'Pantalon', 'Chaleco', 'Vestido', 'Abrigo',\n",
        "               'Sandalia', 'Camisa',   'Zapatilla',  'Bolso',   'Bota']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "### Explorar los datos\n",
        "\n",
        "Exploremos el formato de los datos antes de entrenar el modelo. El bloque de codigo a continuación nos muestra que hay 60.000 imágenes en el conjunto de entrenamiento y 10.000 imágenes en el conjunto de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaOTZxFzi48X"
      },
      "source": [
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocesar los datos\n",
        "\n",
        "El valor de cada pixel en la imágen es un entero en el rango `[0, 255]`. Para que el modelo funcione como corresponde, normalizaremos estos datos al rango `[0,1]`. Creamos una función de normalización y la aplicamos a cada imagen de cada conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NORMALIZADO\n",
        "# Definir la función de normalización\n",
        "def normalize(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Aplicar la normalización usando map y luego configurar el batching y el caching\n",
        "train_dataset_norm = train_dataset.map(normalize)\n",
        "test_dataset_norm = test_dataset.map(normalize)\n"
      ],
      "metadata": {
        "id": "edRl7xkJs5ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "Mostramos las primeras 25 imágenes del conjunto de pruebas y mostramos el nombre de la clase abajo de cada imagen. También verificamos que los datos estén correctos y estaremos listos para armar y entrenar la red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZTImqg_CaW1"
      },
      "source": [
        "# Tomamos una imagen y le quitamos la dimensíon del color haciendo un reshape\n",
        "image, label = tf.data.experimental.get_single_element(test_dataset_norm.take(1))\n",
        "\n",
        "image = image.numpy().reshape((28,28))\n",
        "# Mostramos la imagen\n",
        "plt.figure()\n",
        "plt.imshow(image, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Construir el modelo\n",
        "\n",
        "Construir el modelo requiere configurar las capas del modelo y luego compilarlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Configurar las capas\n",
        "\n",
        "El bloque más básico de construcción de un modelo es una capa. Esta extrae la representación de la data que se le introdujo. Una serie de capas conectadas creará una representación significativa para el problema.\n",
        "\n",
        "Mucho del deep learning consiste en juntar varias capas simples. Varias capas como la `tf.keras.layers.Dense`, tienen parámetros internos que son ajustados mientras se ejecuta el entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos dos modelos para diferencia entre datos normalizados y sin normalizar"
      ],
      "metadata": {
        "id": "U6G3SYw_lA0e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "source": [
        "model_no_norm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_norm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "jHmmeLDo2tDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "Esta red tiene 3 capas:\n",
        "\n",
        "* **Capa de Entrada:** `tf.keras.layers.Flatten` — Esta capa transforma las imágenes de un arreglo bidimensional de 28 $\\times$ 28 pixels a un arreglo unidemensional de 784 pixeles (28\\*28). Esta capa no tiene parámetros para ajustar ya que, solo reforma los datos.\n",
        "\n",
        "\n",
        "* **Capa \"Oculta\":** `tf.keras.layers.Dense`— Una capa densa conectada completamente de 128 neuronas. Cada neurona (o nodo) toma la entrada de los 784 nodos de la capa anterior y ajusta los pesos de acuerdo a los parámetros internos de cada neurona para luego pasar el resultado a la siguiente capa. Aquí la función de activación es una Relu.\n",
        "\n",
        "* **Capa de Salida:**  `tf.keras.layers.Dense` — Una capa compuesta de 10 neuronas, las cuales representan cada clase. Cada neurona toma la salida de todos los nodos anteriores para representar una probabilidad, entre 0 y 1, para cada clase, a través del Softmax. La suma de la salida de todas las neuronas es 1.\n",
        "\n",
        "\n",
        "\n",
        "### Compilar el modelo\n",
        "Antes de que el modelo esté listo para el entrenamiento, necesita unas configuraciones adicionales.\n",
        "\n",
        "* **Optimizador:** Un algoritmo para ajustar los parametros internos durante la ejecución del entrenamiento. Para más información revisa [Optimizers documentation](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam). En este caso se utilizam \"Adam\".\n",
        "* **Función de pérdida:** Un algoritmo para cuantificar que tan bien está funcionando la red durante el entrenamiento, es decir, cuanto difieren los resultados actuales de los esperados (entre menos mejor). Para más información revisa [Losses documentation](https://www.tensorflow.org/api_docs/python/tf/keras/losses). En este caso se utiliza \"Cross Entropy\".\n",
        "* **Métricas:** Usadas para monitorear el entrenamiento. Por ejemplo aquí se utilizará el \"Accuracy\". Para más información revisa [Metrics documentation](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "model_no_norm.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_norm.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DMw9sDgj2w_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Entrenar el modelo\n",
        "\n",
        "Primero, definimos el comportamiento de las iteraciones para el conjunto de entrenamiento:\n",
        "1. Repetir para siempre especificando `dataset.repeat()`. El parámetro `epochs` define cuantas iteraciones del entrenameinto queremos hacer.\n",
        "2. `dataset.shuffle(60000)` aleatoriza el orden en que son entregados los valores en cada iteración. De esta manera, el modelo no puede aprender nada del orden de los datos.\n",
        "3. `dataset.batch(32)` le dice a `model.fit` que use conjuntos de 32 imágenes (batch) y etiquetas cuando se actualizen las variables del modelo. Este número puede ser cambiado dependiendo de las capacidades de nuestro hardware.\n",
        "\n",
        "El entrenamiento es realizado llamando `model.fit`:\n",
        "1. Dar el los datos de entrenamiento usando el conjunto de entrenamiento.\n",
        "2. El modelo aprende a asociar imágenes con etiquetas ajustando los parámetros internos de cada una de las neuronas y sus sesgos (*biases*).\n",
        "3. `epoch=5` limita el entrenamiento a 5 iteraciones completas del conjunto de entrenamiento. Entonces, pasarán un total de 5 * 60000 = 300000 imágenes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "A medida que el modelo se entrena, la pérdida y el accuracy son mostrados. Este modelo alcanza un accuracy de 0.89 aproximadamente, usando el conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Evaluar el accuracy\n",
        "\n",
        "A continuación, comparamos como el modelo se comporta con el conjunto de pruebas (test set). Usaremos todos los ejemplos para obtener la métrica."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIN NORMALIZAR"
      ],
      "metadata": {
        "id": "hbA-xEpKlFj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset_no_norm = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset_no_norm = test_dataset.cache().batch(BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "AWoll-RG0y5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_no_norm.fit(train_dataset_no_norm, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "metadata": {
        "id": "Cy9tdHgnLD_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model_no_norm.evaluate(test_dataset_no_norm, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy en el set de pruebas:', test_accuracy)"
      ],
      "metadata": {
        "id": "ebUVZZT1lPhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMALIZADO"
      ],
      "metadata": {
        "id": "dVJ22NsUlIfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset_norm = train_dataset_norm.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset_norm = test_dataset_norm.cache().batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "b_-e6WUx2-cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_norm.fit(train_dataset_norm, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "metadata": {
        "id": "ZdEwgxePHbzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model_norm.evaluate(test_dataset_norm, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy en el set de pruebas:', test_accuracy)"
      ],
      "metadata": {
        "id": "83Ee7RblIQXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "Como podemos darnos cuenta, el accuracy en el conjunto de pruebas es menor que el del conjunto de entrenamiento. Esto es completamente normal, debido a que el modelo fue entrenado con el conjunto de entrenamiento. Cuando el modelo ve imágenes que nunca ha visto, podemos esperar que el rendimiento de la red baje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## Hacer predicciones y explorar\n",
        "\n",
        "Con el modelo entrenado, podemos utilizarlo para hacer predicciones sobre algunas imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccoz4conNCpl"
      },
      "source": [
        "for test_images, test_labels in test_dataset_norm.take(1):\n",
        "  test_images = test_images.numpy()\n",
        "  test_labels = test_labels.numpy()\n",
        "  predictions = model_norm.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "source": [
        "predictions.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Aqui, el modelo ha predicho una etiqueta para cada imagen en el conjunto de pruebas. Veamos la primera predicción."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "\n",
        "Una predicción es un arreglo de 10 números. Estos describen la \"confianza\" del modelo de que esa imagen corresponde a cada una de las clases. Podemos ver cual es la clase con la mayor confianza:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "El modelo tiene la mayor confianza en que esta es un abrigo, o `class_names[4]`. Y podemos ver la etiqueta que corresponde, a ver si es correcta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Podemos graficar esto para ver la ver el conjunto completo de las 10 clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvYmmrpIy6Y1"
      },
      "source": [
        "def plot_image(i, predictions_array, true_labels, images):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Ov9OFDMmOD"
      },
      "source": [
        "Veamos la primera imagen, sus predicciones y el arreglo de predicciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV5jw-5HwSmO"
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko-uzOufSCSe"
      },
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "Grafiquemos varias imágenes con sus predicciones. Las predicciones correctas son azules y las incorrectas: rojas. El número muestra la confianza, en porcentaje, de la etiqueta predicha. Es importante notar que puede estar equivocada aún con mucha confianza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQlnbqaw2Qu_"
      },
      "source": [
        "# Imprime las primeras X imagenes de prueba, su etiqueta predicha y la etiqueta correcta\n",
        "# Predicciones correcta en azul y las incorrectas en rojo\n",
        "num_rows = 6\n",
        "num_cols = 4\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}